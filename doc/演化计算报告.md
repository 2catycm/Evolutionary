# Evolving to Evolve: A Review on Mutation Based Evolutionary Algorithm

<div align="center">
    叶璨铭, 12011404 <br>
    南方科技大学 <br>
    12011404@mail.sustech.edu.cn <br>
</div>
<!-- SUSTech CS Course of EA with its Application, Assignment 1, First Report, March 2023 -->

---

## 摘要

[TOC]

---

## 1. 绪论

### 1.1 研究目的

在本次project中，我们需要**设计并实现演化算法**去黑箱优化一组基准测试函数。测试函数拥有以下特点：

- 优化问题为单目标优化（single objective），即测试函数的值域为实数域 $y\in \R$。
- 测试函数的定义域为$x\in D, D=[lb, ub]^d\subseteq \R^d$, 即考虑了边界约束（bound constrained）。
- 优化目标是最小值及其解，即求$argmin_{x \in D}\ y(x)$。
- 优化类型为**黑箱优化**，即可以**消耗评估次数**来获得函数在**任何具体输入上的输出值**，但是无法得知函数的形式。
  - 函数可能可导，也有可能不可导。
    - 优化过程不知道函数形式，因此不可以利用导函数（一个函数解析式，需要用到测试函数的函数解析式）的信息。
    - 但是不排除用黑盒方法估计导数。
  - 函数可能是单峰函数（即有且只有一个局部最优解），也可能是多峰函数
  - 函数可能是确定性函数，也可能是非确定性函数。

### 1.2 本文探讨的主要问题

解的搜索空间是离散空间（可数无穷或有限取值的集合）的问题称为组合优化问题，而解的搜索空间为连续空间的问题称为**数值优化问题**。[^1]

- 一般认为组合优化问题更难。
- 黑箱函数的值域似乎认为对问题的难度不重要。没有找到文献描述此事。

## 2. 方法论

### 2.1 已有研究演化算子原理及分析

演化算子本质上是**种群映射到种群的一个函数**，表示种群演化的过程。

从演化计算的阶段来说，我们可以把演化算子分为

- 种群初始化算子
  - 从一个**空集种群**随机或确定地产生一个**给定大小的种群**。
  - 我们往往可以先验地假设模型的最优解均匀/正态地分布在定义域上。
  - 然后根据我们搜索的次数，决定我们初始化种群是否集中（方差）。
  - 我们可以尝试假设最优解在定义域上服从柯西分布，比起高斯分布，这样可以尽可能广的覆盖整个定义域。
- 种群进化算子
  - 我们在Lecture2中重点学习过这一类算子。
  - 主要包括**基因重组算子和基因突变算子**。具体有多种可能的实现方式。
  - 这两个都是借鉴于生物学现象。
  - 针对这一类算子的选择，我们可能会有下面的疑问
    - 将高斯分布改成柯西分布，效果就变好了，理由是柯西分布步长绝对值期望无穷，变化很宽。
      - 单纯把高斯分布的step_size调大一些和改成柯西分布是有本质区别的，为什么不采纳前者？
      - 柯西分布是特殊的t分布。选择其他自由度的t分布是否可以进一步提高性能？
    - 在讲到nonuniform mutation时，姚老师问我们为什么perturbation来自均值为0的分布，而不是有一个方向。
      - 其实如果能够通过差分估计梯度，是不是也可以让均值是估计出来的梯度呢？
- 种群选择算子
  - 从一个大的种群映射到一个小的给定大小的种群。
  - 我们在Lecture3中重点学习过这一类算子。
  - 主要包括**基于适应度值的选择和基于适应度排名的选择以及锦标赛选择**三种方式。

- 超参数初始化、进化与选择算子
  - 我们这里研究的超参数主要包括两点，种群大小和移动步长。

  - 姚老师课上指出，移动步长在演化计算中的作用类似于寄生虫在生物进化中的作用[^2]
    - 移动步长能够决定解的变化速度，因此动态调整超参数的大小很重要。
    - 文献中有一定的数学分析支持一个特定的经验公式来实现初始化和进化。
    - 认为移动步长不需要专门有自己的选择算子。

  - 自然地，我们可以提出一些问题
    - 问题本身不像寄生虫，更像是一种社会文化或意识形态：人们是否愿意改变自己。
    - 目前的“自适应算法”的实现方式是寄生虫，他们只能跟随主体生存或灭亡，适应度不由他们决定。
    - **问题的建模和问题的解决方案之间关联不大，因此我们也可以不这样实现，可以探索其他思路。**已有的算法可以作为benchmark进行对比。


### 2.2 演化算子的算法代码实现

进化算法在不同的步骤都有很多的仿生策略可以备选，假设有n个步骤，每个步骤有m种策略，要将感兴趣的进化算法全部实现需要 $O(m^n)$ 的代码量。好在，我们有软件工程的设计模式理论来解决这一问题。尽管MATLAB的面向对象功能不是很平易近人，MATLAB的函数设计得还算可以，容易把握。我们可以基于MATLAB的语法，选择策略模式与模版模式来解决这一问题。

具体而言，将每一个策略写为函数，标记其为相应策略的一部分。具体进化算法在计算之前，接收一个strategies的函数句柄数组，随后利用数组中的策略函数进行演化计算。

策略模式体现在程序运行过程中，可以修改调用演化算法所用的策略，对应于面向对象设计策略模式中has a behavior对象关系；模版模式则体现在子策略由子函数具体实现，而算法的模版调用抽象接口函数的顺序不发生改变。

OPTIMISERS
│  EA_all.m 演化算法模版
│  EA_cauthy_adaptive.m 	示例：柯西自适应策略算法
│  EA_normal.m 					示例：正态策略算法
│  EA_normal_adaptive.m 	示例：正态自适应策略算法
│  optimisers_config.m 		模块初始化函数。主要是加载子文件夹到MATLAB工作路径。
│  README.md						本文档，解释说明运行方式和代码规范。
│  software_test.mlx 			软件测试，检查所有算子是否符合预期地对种群进行操作。
│
├─strategies
│      hyper_init_strategy.m		超参数初始化策略集
│      hyper_update_strategy.m 超参数更新策略集
│      initialization_strategy.m	解初始化策略集
│      mutation_strategy.m		变异策略集
│      selection_strategy.m		选择策略集
│
└─utils
        get_strategy_combination.m
        strategy_unwrap.m
        utility_function_paralleled.m

## 3. 实验: 探究不同演化算法策略对演化算法优化的性能的影响

### 3.1 实验模型：性能评价标准

针对单个演化算法，我们要评价其效果，可以从以下角度去考虑[^7]

- Convergence rate.
- Precision.
- Robustness.
- General performance.

而针对多个演化算法之间性能的差距，我们本次只考虑最后的优化结果是否和其他算法有统计学意义的显著差异。



### 3.2 实验设置：实验材料、仪器与实验常数设置

实验材料、仪器与实验常数不是实验本身要探究的对象，而是保持不变的无关变量。无关变量并不是说其不影响实验结果，相反，他们对实验的信效度有着重要的作用。无关是其与实验设计要研究目的无关，需要控制保持相等。实验的因变量是不同的演化算法（策略不同或者参数不同）。

####  3.2.1 实验材料与探索性分析

如1.1中所述，本次project中，我们使用了10个待优化函数作为测试基准。测试函数又称人造地标（**artificial landscapes**）[^7]，是我们的实验材料。人造地标起到了和机器学习中的常见数据集类似的作用，用于快速验证一个新的优化算法是否有效。
| 编号         | 1      | 2                  | 3        | 4                            |
| ------------ | ------ | ------------------ | -------- | ---------------------------- |
| 名称         | 球模型 | 广义Rosenbrock函数 | 阶梯函数 | 带均匀分布噪声的四次函数[^6] |
| 维度         | 30     | 30                 | 30       | 30                           |
| 理论最小值   | 0      | 0                  | 0        | 0                            |
| 最大评估次数 | 300000 | 300000             | 300000   | 300000                       |

| 5        |  6      | 7      | 8        | 9     | 10      |
|------- |  ------ | ------ | -------- | ----- | ------- |
| 广义Schwefel226问题 | Ackley函数 | 广义Schwefel222问题 | Hölder的表格函数 | 三峰函数 | Michalewicz函数 |
|30       |  30     | 30     | 2        | 2     | 2       |
| -12569.5 |  0      | 0      | -19.2085 | 0     | -1.8013 |
| 300000   |   300000 | 300000 | 20000    | 20000 | 20000   |

针对这个数据集表格，我们很自然的会有很多疑问：

- 理论最小值问题
  
  - 我们注意到有些函数是随机函数，运气不好的话最小值算出来反而不如我们优化算法那一次算出来的值小。
  
  - 要想自动化地计算S1和S2，我们需要从benchmark读取理论最小值。
  
    ```matlab
    % 老师提供的代码
    benchmark(1).optimum=zeros(1,benchmark(1).dimension);
    % 使用 global_min = objective(optinum)读取理论最小值是不准确的，因为随机性。
    % 正确方法：在benchmarkInfo.m 增加代码。
    % 为了不破坏老师的代码，维持开闭原则，我们也可以在自己写的NewTestEA.m中增加这些代码
    optvals = [0	0	0	0	-12569.5	0	0	-19.2085	0	-1.8013];
    for index = 1:10
        benchmark(index).optival = optvals(index);
    end
    ```
  
- 名称问题

  - 为什么研究者们把函数1叫做球模型？这明明就是抛物线(parabola)或高维的抛物面。球根本就不是函数，而是点的集合，在目标函数为定值的时候才是球。

  - 回答：这是两种不同看待函数的视角。

    - 从x,y,z做出三维空间中的函数图像，这是抛物线的观点，如图所示:

      <img src="演化计算报告.assets/image16783738604730.png" alt="img" style="zoom: 33%;" />

    - 而有些研究者习惯从上往下看，直接在二维输入空间做出颜色。

      <img src="演化计算报告.assets/image16783737138520.png" alt="img" style="zoom:33%;" />

    - 颜色与等高线类似，而等高线是圆或者球。

- 维度与最大评估次数的关系？为什么这样设置？

  - 容易看出评估次数的选择与维度n成正比。
  - 遵循了经验公式$nbEvaluations=n\times10000$。
  - 

- 对于30维的函数，如何探究其性质？

  - 注意到30维的图像部分都是顺序无关的(x的不同维度之间交换不改变值)。
  - 另外一些也很容易可以得到类似性质的二维版本函数。
  - 因此我们可以将`benchmark`文件夹复制一份`benchmark2d`, 然后修改d，随后探究性质。


在wiki[^7]中已经有部分函数的图像。这种在二维坐标系上用颜色表示目标函数大小的图像可以称为平面颜色图或者**伪彩图**。[^8]我更喜欢抛物面那样的三维图，可以很直观的看出要优化的山峰的地形，使用MATLAB绘图将10个函数全部画出三维图，如附录1所示。

姚新教授的快速演化规划算法在**单峰函数上收敛速度更快**，最终结果不一定更好（未调参时）；而在**多峰函数**上快速演化算法有更好的跳出局部最优解的能力，因此**最终效果也会更好**。[^2]因此，我们在之后的实验中，应当注意到本次实验中sphere,rosenbrock, schwefel222是单峰函数，而其他函数都是多峰函数。[^2]本文中我们说明一个函数是不是单峰函数，是因为文献中其他研究者通过数学方法求导证明过其性质，这种确认方法有两个问题：

- 在实际的黑箱优化中，我们**无法了解测试函数**，不可能从数学上证明起是否是单峰函数。
  - 而我们很了解比如说姚新教授的快速演化规划算法的性质，想要根据测试函数的大致形状来决定使用柯西分布还是高斯分布的时候，我们无法决策。
- 实际上我们从直观的图像上来看，阶梯函数、带均匀分布噪声的四次函数，Archey函数，**似乎也是单峰函数**。

针对第二个问题，这种“似乎”性其实反映了一种概率论的**随机采样**的思想。我们知道计算机绘制图像的本质是在定义域上采样**有限的点**计算值然后进行表示。如果在演化算法采样种群的过程中，我们的演化算子的步长与我们采样的步长差不多大，当然也可以认为这个函数就是单峰函数。

而针对第一个问题，我们也可以引入统计的方法来解决这一问题。具体而言，可以使用Hartigan’s dip test来检验一个黑箱函数的采样值是否服从单峰分布，从而从统计学的意义用**有限的样本检验黑箱函数是否大概率可以认为是单峰函数**。[^9]

针对第一个问题还有一种**优化理论**上的答案。凸函数可以说是可导的单峰函数。给定一个知道数学公式的目标函数，可以通过一些逻辑规则(基本的凸函数和保持凸性的操作)构建专家系统，使用符号主义的人工智能搜索方法去判断一个函数是不是凸函数。[^10]

#### 3.2.2 实验仪器

操作系统：

```
版本	Windows 11 专业版
版本	22H2
操作系统版本	22623.1325
```

MATLAB版本：

```log
9.13.0.2105380 (R2022b) Update 2
```

### 3.3 实现难点与解决方案

#### 3.3.1 MATLAB中如何生成柯西分布的随机数？

MATLAB本身标准库并没有可以生成柯西分布随机数的函数，只有均匀分布和正态分布。而现代C++标准库与Python numpy库中是有的。因此我们需要自己实现。

根据柯西分布的不同等价定义，相应的也有不同的实现思路。

- 视角1：柯西分布是一个概率密度函数。
  - 要生成分布函数（cdf）为F(x)的r.v， 只需要将$F^{-1}$作用于(0,1)上均匀分布的随机数即可。[^11]
  - 我们需要求柯西分布的累积分布函数的解析式F及其反函数。
  - $F^{-1}(x)=\gamma tan((x-\frac{1}{2})*\pi)+x_0$
  - 其中$x_0$是峰值位置，$\gamma$是最大值一半处的一般宽度的尺度参数。
- 视角2：柯西分布是特殊的t分布。
  - 而t分布是一种抽样分布。设X~$N(0,1)$, Y~$\chi^2(n)$, X与Y是独立随机变量、
  - 则随机变量的函数（一个新的随机变量）t=$\frac{X}{\sqrt{Y/n}}$服从自由度为n的t分布。[^11]
  - n=1时，t分布是柯西分布.[^11]
  - 那么，我们只需要随机采样两个两个高斯分布的随机变量相除即可。

这两种方法都有可能产生inf，前一种方法可能好一些，因为pi是不精确的。

我们在编程时需要一定的检查。

#### 3.3.2 MATLAB性能问题

 

### 3.4 实验设计、结果与分析

#### 3.4.1 柯西变异算子与正态变异算子的性能分析实验

正态变异算子

| f1          | f2          | f3   | f4          | f5           | f6         | f7          | f8           | f9          | f10          | S1 Eq.(3)   |
| ----------- | ----------- | ---- | ----------- | ------------ | ---------- | ----------- | ------------ | ----------- | ------------ | ----------- |
| 5.322470469 | 2675.659916 | 0    | 2.896372161 | -604664.8028 | 574.432396 | 137529493.2 | -771.4555567 | 5.973416092 | -91.75462158 | 136927229.5 |



#### 3.4.2 不同步长初值对性能的影响分析实验



#### 3.4.3 演化策略的组合优化实验



---

## 5. 总结与未来展望

通过本次项目的理论分析与代码实验，我们

- 

由于时间仓促，有很多有趣的想法未能详细调研文献和进行代码实现，我将这些想法作为未来展望列举，希望在后续课程学习中能够逐一探究：

- 基于梯度估算来让问题转为有梯度优化问题
  - 导数的本质定义是输入变量发生微小的变化时，输出值发生的变化与输入变量变化值的比值的极限。如果有多个输入变量，或者说一个输入向量，则输入向量的每一个元素有一个导数，拼接起来就是梯度。
  - 因此，通过消耗一定的fitness计算次数，可以逐一改变每一个变量，测算导数。
- 让演化计算更加接近生物学的实际情况，使其具有生物学意义，从而解释其优越性。
  - 达尔文进化的一个成立前提是可繁殖的生物体在一个仅能容纳有限个体的环境中生存。[^1]
    - 我们高中生物学习过S型曲线和J型曲线。
    - 种群数量越大，适应度函数整体应该变低。
  - 然而，我们的演化计算虽然成功模拟了“非同源染色体自由组合”（两个实数向量交叉互换算子）和”非姐妹染色单体交叉互换“（单个实数的二进制表示交叉互换）和基因突变。
  - 但是我目前看到的算法没有对种群的数量有所改变。每一轮循环种群的数量都是population_size，无法体现种群内部的生存竞争。连进化论最基本的假设都没有模拟出来。
  - 文献[^1]解释说保持不变本身体现了稳态下的环境，population_size就是最大的容纳量。文献[^1]强调种群是进化的单位，个体不具备行为能力。更加复杂的模拟方法有一些基于地理位置，体现生殖隔离。[^1]
- 设计奖赏函数将问题转化为强化学习问题
  - 假设初始化是一样的，具有初始的fitness。
  - 状态State就是种群，行动Action就是演化算子。
  - 设计奖赏函数为fitness的变化值，那么累计奖赏就相当于是最后的fitness值。强化学习算法可以使得累计期望奖赏接近最大，因此也可以用于优化问题。

- 纯粹使用随机生成点，退化为重置概率为1的随机重置策略的演化算法。
  - 每一轮算法都均匀分布的生成点，下一轮的值完全与上一轮无关。记录并更新最优的适应度。
  - 这样也可以做优化，没有任何方向，不会缩小搜索范围，按照[^12]的说法，这样做具有很强的探索性，给定无穷时间，适应度依概率收敛于最优适应度。文献[^12]认为模拟退火算法之所以成功就是因为比起爬山法更加具有探索性，充分利用了给定的时间限制。
- 设计运动学模型和观测模型将问题转化为贝叶斯滤波问题
  - 我们在智能机器人中学习过贝叶斯滤波这种方法，可以估计状态的后验概率，应用于机器人的同步定位与建图。
  - 种群很像是粒子滤波里面的粒子群，表达的是最优解所处位置的概率分布。我们观测到一个新的值，可以修正这个概率分布。我们根据移动的速度，可以估计最优解移动的方向。

- 本文试图重点探究的问题：让机器自己学会如何使用一个优化算法，转换为机器学习问题。

  - 问题定义与评价方式

    - 我们上文已经初步探究了使用整数规划算法或者”学生y调参算法“来让机器选择演化策略来构建演化算法，从而在测试基准上达到更优秀的S1值。
    - 实际上，我们可以扩充测试基准的函数数量，形成一个更加有统计意义的数据集。
    - 使用训练集训练演化算法，使用测试集评估得到的演化算法的泛化性能。

  - 一些难点

    - 我们上文只选择了演化策略，事实上同一演化算法阶段不同演化策略的函数接口未必相同，有不同的输入参数可以调，比如柯西分布和高斯分布基本上有意义相同的两个参数：众数和步长，但是t分布就多出一个自由度参数。
    - 对于演化计算，输入变量的维度是固定的，这就导致了演化计算具有一定的死板性，无法针对这种问题直接优化。我上文的操作相当于是一个二阶段优化：先优化出最优策略组合（离散的值），然后根据最优策略组合优化最优参数(连续值)。

  - 一些有趣的想法

    - 这些参数可以认为和问题限制有关系，比如维度、种群大小、限制的评估数、变量的区间长度等，我们可以猜想正比关系，或者其他复杂的关系。

    - 这个关系本身过于复杂，而且是经验设置的，对于这种问题，可以用神经网络，因为神经网络可以逼近任何实值函数！

    - 由于优化是一个过程，参数在过程中发生变化，因此神经网络可以是循环神经网络！

      







# 参考文献

[^1]: A. E. Eiben and J. E. Smith. Introduction to Evolutionary Computation. Springer-Verlag, Berlin, 2015.
[^2]: Xin Yao, Yong Liu和Guangming Lin, 《Evolutionary programming made faster》, *IEEE Trans. Evol. Computat.*, 卷 3, 期 2, 页 82–102, 7月 1999, doi: [10.1109/4235.771163](https://doi.org/10.1109/4235.771163).
[^3]: Y.-X. Wang, Q.-L. Xiang和Z.-D. Zhao, 《Particle swarm optimizer with adaptive tabu and mutation: A unified framework for efficient mutation operators》, *ACM Trans. Auton. Adapt. Syst.*, 卷 5, 期 1, 页 1–27, 2月 2010, doi: [10.1145/1671948.1671949](https://doi.org/10.1145/1671948.1671949).
[^4]: T. Bäck和H.-P. Schwefel, 《An Overview of Evolutionary Algorithms for Parameter Optimization》, *Evolutionary Computation*, 卷 1, 期 1, 页 1–23, 3月 1993, doi: [10.1162/evco.1993.1.1.1](https://doi.org/10.1162/evco.1993.1.1.1).
[^5]: [Optimization Test Functions and Datasets (sfu.ca)](https://www.sfu.ca/~ssurjano/optimization.html)


[^7]: 《Test functions for optimization》, *Wikipedia*. 2023年1月12日. 见于: 2023年3月9日. [在线]. 载于: https://en.wikipedia.org/w/index.php?title=Test_functions_for_optimization&oldid=1133254545

[^8]: 《在matlab中绘制二维颜色图表示z轴，并添加等高线》, 知乎专栏. https://zhuanlan.zhihu.com/p/49615571 (见于 2023年3月9日).
[^9]: P. Juillion, 《What is Hartigan’s dip test? - Studybuff》, 2020年3月12日. https://studybuff.com/what-is-hartigans-dip-test/ (见于 2023年3月10日).
[^10]: [如何快速判断目标函数的凸性？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/49902644)

[^11]: J. A. Rice, 数理统计与数据分析. <a href="https://book.douban.com/press/2793">机械工业出版社</a>  <br>                 <span class="pl">原作名:</span> Mathematical statistics and data analysis, 2011. 见于: 2023年3月10日. [在线]. 载于: https://book.douban.com/subject/6508744/

[^12]: Stuartj. Russell, PeterNorvig, 诺维格, 罗素, 祝恩和殷建平, 《人工智能:一种现代的方法》, 清华大学出版社, 2013, doi: [9787302331094](https://doi.org/9787302331094).



# 脚注
[^6]: 根据代码实现，“y=sum(idx.*(x.^4))+rand;”， rand为U(0,1)分布

# 附录

广义Rosenbrock函数  阶梯函数  带均匀分布噪声的四次函数

广义Schwefel226问题  Ackley函数  广义Schwefel222问题  Hölder的表格函数  三峰函数  Michalewicz函数

## 附录1: 10个函数三维图形

| 编号 | 函数名                   | 图像                                                         |
| ---- | ------------------------ | ------------------------------------------------------------ |
| 1    | 球模型                   | <img src="演化计算报告.assets/f1-sphere.png" alt="f1-sphere" style="zoom:48%;" /> |
| 2    | 广义Rosenbrock函数       | <img src="演化计算报告.assets/f2-rosenbrock.png" alt="f2-rosenbrock" style="zoom:48%;" /> |
| 3    | 阶梯函数                 | <img src="演化计算报告.assets/f3-step.png" alt="f3-step" style="zoom:48%;" /> |
| 4    | 带均匀分布噪声的四次函数 | <img src="演化计算报告.assets/f4-noisyQuartic.png" alt="f4-noisyQuartic" style="zoom:48%;" /> |
| 5    | 广义Schwefel226问题      | <img src="演化计算报告.assets/f5-schwefel226.png" alt="f5-schwefel226" style="zoom:48%;" /> |
| 6    | Ackley函数               | <img src="演化计算报告.assets/f6-ackley.png" alt="f6-ackley" style="zoom:48%;" /> |
| 7    | 广义Schwefel222问题      | <img src="演化计算报告.assets/f7-schwefel222.png" alt="f7-schwefel222" style="zoom:48%;" /> |
| 8    | Hölder的表格函数         | <img src="演化计算报告.assets/f8-holder.png" alt="f8-holder" style="zoom:48%;" /> |
| 9    | 三峰函数                 | <img src="演化计算报告.assets/f9-camel3.png" alt="f9-camel3" style="zoom:48%;" /> |
| 10   | Michalewicz函数          | <img src="演化计算报告.assets/f10-michal.png" alt="f10-michal" style="zoom:48%;" /> |

